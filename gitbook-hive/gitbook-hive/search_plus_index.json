{"./":{"url":"./","title":"Hive","keywords":"","body":"HiveHive Hive 는 Hadoop의 데이터를 다루는 SQL 질의의 표준이다. HDFS의 데이터를 SQL로 접근할 수 있는 방법을 제공한다. Hive Query Language, 즉 HQL을 사용하여 RDBMS의 표준 SQL과 비슷한 의미와 함수를 가지며, RDBMS 경험자라면 손쉽게 사용할 수 있다. 또한, HDFS 상에서 High 레벨의 데이터 모델이며, 테이블과 같은 구조를 제공한다. Hive는 table, partition, bucket, 세개의 데이터 구조를 지원하고 table을 HDFS 디렉토리에 대응하고, 이를 파티션으로 분할할 수 있으며, 파티션을 버킷으로 차례대로 나눌 수 있다. TIMESTAMP, STRING, FLOAT, BOOLEAN, DECIMAL, DOUBLE, INT, SMALLINT, BIGINT 같은 primitive(원시) 데이터 포매스이 대부분을 지원하고 UNION, STRUCT, MAP, ARRAY 와 같은 복잡한 데이터 연산을 지원한다. Hive Architecture [출처](https://medium.com/plumbersofdatascience/hive-architecture-in-depth-ba44e8946cbc) 위 그림은 하이브 아키텍처를 그린것으로, metadata store 는 내장, 로컬, 원격 데이터베이스를 사용할 수 있다. Apache Thrift를 통해 Hive에 접근할 수 있고, CLI와 웹 인터페이스를 활용할 수 있다. Hive의 장점을 모아 보면 다음과 같다 Hive는 Map/Reduce 보다 간단하고, 간단한 질의 모델을 개발방법을 제공한다. HQL과 SQL 문법이 비슷하다 쉽게 분석할 수 있는 여러 API, 함수를 제공한다. 많은 데이터 집합에서 동일한 타입의 질의 응답 시간은 여타 질의 응답 시간보다 일반적으로 훨씬 빠르다 여러 컴퓨팅 프레임워크에서 동작한다. HDFS에 애드혹 질의를 할 수 있다. Hive는 사용자가 정의한 함수, 스크립트, 사용자 I/O등의 확장가능한 기술을 제공한다. "},"Installation.html":{"url":"Installation.html","title":"??","keywords":"","body":"설치Hive 1.2.2MySQL 설치Hive 다운로드설정에러해결설치 Hive 1.2.2 Hive는 기본 메타데이터 저장소로 derby를 사용하지만, 외부 데이터 베이스로 MySQL, PostgreSQL를 사용할 수 있다. MySQL은 메타데이터를 저장할 노드에만 설치하면 된다. MySQL 설치 yum -y install http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm yum -y install mysql-community-server systemctl start mysqld systemctl enable mysqld 최초 실행시 아래처럼 임시 비밀번호를 조회하여 접속할 수 있다. cat /var/log/mysqld.log ## [Note] A temporary password is generated for root@localhost: ****** 접속 후 비밀번호를 재설정 해줘야 한다. mysql -u root -p ALTER USER 'root'@'localhost' IDENTIFIED BY '*****'; FLUSH PRIVILEGES; SET GLOBAL validate_password_policy=LOW; SET GLOBAL validate_password_length=4; use mysql CREATE USER 'hive'@'%' IDENTIFIED BY 'hive'; GRANT ALL ON *.* TO 'hive'@'%' IDENTIFIED BY 'hive'; FLUSH PRIVILEGES; exit hive 접속 테스트 mysql -u hive -p Hive 다운로드 wget http://mirror.apache-kr.org/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz tar xvf apache-hive-1.2.2-bin.tar.gz mv apache-hive-1.2.2-bin /opt/hive-1.2.2 chown -R hive:hadoop /opt/hive-1.2.2 chmod -R g+w /opt/hive-1.2.2 설정 vim /etc/profile.d/hive.sh export HIVE_HOME=/opt/hive-1.2.2 export PATH=$PATH:$HIVE_HOME/bin:$HIVE_HOME/conf source /etc/profile.d/hive.sh cd $HIVE_HOME/conf cp hive-default.xml.template hive-site.xml cp hive-env.sh.template hive-env.sh cp hive-exec-log4j.properties.template hive-exec-log4j.properties cp hive-log4j.properties.template hive-log4j.properties 설정파일 수정 : vim hive-env.sh export HADOOP_HOME=/opt/hadoop-2.7.7 export HIVE_CONF_DIR=/opt/hive-1.2.2/conf vim hive-site.xml ... javax.jdo.option.ConnectionURL jdbc:mysql://centos-namenode-1/hive?createDatabaseIfNotExist=true JDBC connect string for a JDBC metastore javax.jdo.option.ConnectionDriverName com.mysql.jdbc.Driver Driver class name for a JDBC metastore javax.jdo.option.ConnectionUserName hive Username to use against metastore database javax.jdo.option.ConnectionPassword hive password to use against metastore database ... JDBC 다운로드 : cd $HIVE_HOME/lib wget http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.27.tar.gz tar xvf mysql*.gz cp mysql-connector-java-5.1.27/*.jar $HIVE_HOME/lib HDFS hive 계정 및 디렉토리 생성 : hdfs dfs -mkdir -p /user/hive/warehouse hdfs dfs -chown -R hive:hadoop /user/hive hdfs dfs -chmod -R g+w /user/hive/ Mysql 메타데이터 테이블 생성 : $HIVE_HOME/bin/schematool -initSchema -dbType mysql 접속 테스트 : hive 에러해결 Exception in thread \"main\" java.lang.RuntimeException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: ${system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D : 다음을 hive-site.xml 끝에 추가한다 system:java.io.tmpdir /tmp/hive/java system:user.name ${user.name} $SPARK_HOME/lib/spark-assembly-*.jar 찾을 수 없다 에러, Spark 2.0 버전과의 호환성 문제, $HIVE_HOME/bin/hive 스크립트 수정 vim $HIVE_HOME/bin/hive # add Spark assembly jar to the classpath if [[ -n \"$SPARK_HOME\" ]] then sparkAssemblyPath=`ls ${SPARK_HOME}/jar/*.jar` CLASSPATH=\"${CLASSPATH}:${sparkAssemblyPath}\" fi "},"Data_Types.html":{"url":"Data_Types.html","title":"Data Types","keywords":"","body":"Data TypesNumeric TypesDate/Time TypesString TypesMisc TypesComplex TypesData Types 공식문서 Numeric Types Numeric Types 설명 TINYINT 1-byte signed integer, -128 ~ 127 SMALLINT 2-byte signed integer, -32768 ~ 32767 INT 4-byte signed integer, -2147483648 to 2147483,647 BIGINT 8-byte signed integer, -9223372036854775808 ~ 9223372036854775807 FLOAT 4-byte 단일 정밀도 부동 소수점 DOUBLE 8-byte 배정밀도 부동 소수점 숫자 DOUBLE PRECISION DOUBLE의 alias, Hive 2.2.0부터 지원 DECIMAL JAVA의 BigDecimal 타입과 동일, 오차없이 실수를 표기 할 수 있다 NUMERIC Hive 3.0.0부터 지원, DECIMAL과 동일함 Date/Time Types Date/Time Types 설명 예시 TIMESTAMP yyyy-mm-dd hh:mm:ss[.f...] 포맷의 년,달,일,시간,분,초,밀리초 로 표현한다. 2013-01-01 12:00:01.345 DATE YYYY-­MM-­DD 포맷의 년,달,일로 날짜를 표기한다. 2013-01-01 String Types String Types 설명 예시 STRING ' 또는 \" 로 표현되는 문자열 포맷, 최대 길이는 255 'Boos' or \"Books\" VARCHAR 가장 큰 문자열 포맷, 최대 길이는 65355, 길이는 넘어가면 긴 부분은 잘려나간다 'Books' or \"Books\" CHAR VARCHAR와 비슷하지만 255크기로 고정되어 있다. 255보다 작으면 나머지는 빈칸으로 채워 255크기를 맞춘다 'Books' or \"Books\" Misc Types |Misc Types|설명| |BOOLEAN|TRUE or FALSE| |BINARY|STRING 이다| Complex Types Complex Types 설명 예시 ARRAY ARRAY, 데이터 타입을 가진 배열 집합 ['apple','orange','mango'] MAP MAP, (K:V)키값형식의 데이터 집합, {1:\"apple\", 2: \"orange\"} STRUCT STRUCT, 데이터 타입 상관없이 사용자 정의 가능한 배열 집합 {1, \"apple\"} UNION UNIONTYPE, 모든 데이터 타입 중 하나의 데이터 타입만 갖는 집합 {2:[\"apple\", \"orange\"]} "},"HiveQL_DDL.html":{"url":"HiveQL_DDL.html","title":"DDL","keywords":"","body":"DDLDDL Hive에서의 DDL은 다음과 같이 구분지을 수 있다. CREATE DATABASE/SCHEMA, TABLE, VIEW, FUNCTION, INDEX DROP DATABASE/SCHEMA, TABLE, VIEW, INDEX TRUNCATE TABLE ALTER DATABASE/SCHEMA, TABLE, VIEW MSCK REPAIR TABLE (or ALTER TABLE RECOVER PARTITIONS) SHOW DATABASES/SCHEMAS, TABLES, TBLPROPERTIES, VIEWS, PARTITIONS, FUNCTIONS, INDEX[ES], COLUMNS, CREATE TABLE DESCRIBE DATABASE/SCHEMA, table_name, view_name, materialized_view_name "},"HiveQL_DDL_Database.html":{"url":"HiveQL_DDL_Database.html","title":"Database","keywords":"","body":"Database 관리CreateDropAlterUseDatabase 관리 Create CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATION hdfs_path] [WITH DBPROPERTIES (property_name=property_value, ...)]; DATABASE|SCHEMA , 둘중 하나를 고르면 되며 같은 의미이다. Drop DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE]; DROP 실행시 데이터베이스가 비어있지 않을 경우, RESTRICT 상태로 대체한다. 테이블과 같이 날리고 싶을 경우 DROP DATABASE ...CASCADE를 실행 해주면 된다. Alter -- 구조 변경 시 ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, ...); -- 소유권 변경 ALTER (DATABASE|SCHEMA) database_name SET OWNER [USER|ROLE] user_or_role; -- 파일 저장 경로 변경 ALTER (DATABASE|SCHEMA) database_name SET LOCATION hdfs_path; The ALTER DATABASE ... SET LOCATION statement does not move the contents of the database's current directory to the newly specified location. It does not change the locations associated with any tables/partitions under the specified database. It only changes the default parent-directory where new tables will be added for this database. This behaviour is analogous to how changing a table-directory does not move existing partitions to a different location. Use USE database_name; USE DEFAULT; USE는 현재 HiveQL 명령을 실행할 데이터베이스를 지정한다. "},"HiveQL_DDL_table.html":{"url":"HiveQL_DDL_table.html","title":"Table","keywords":"","body":"Table 관련CreateStorage FormatsRow Formats & SerDeTable 관련 Create CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name [(컬럼명 data_type [제약조건] [COMMENT col_comment], ...] [COMMENT table_comment] [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] [SKEWED BY (col_name, col_name, ...)] ON ((col_value, col_value, ...), (col_value, col_value, ...), ...) [STORED AS DIRECTORIES] [ [ROW FORMAT row_format] [STORED AS file_format] | STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)] ] [LOCATION hdfs_path] [TBLPROPERTIES (property_name=property_value, ...)] [AS select_statement]; data_type 에는 Data Types를 참고 Storage Formats STORED AS 는 테이블저장 포맷을 지정할 수 있다. 아래는 지원하는 파일 포맷이다. Storage Format 설명 STORED AS TEXTFILE default인 저장 포맷, plain text files로 저장 된다. STORED AS SEQUENCEFILE Stored as compressed Sequence File. STORED AS ORC Stored as ORC file format. Stores column-level metadata. STORED AS PARQUET Stored as Parquet format for the Parquet columnar storage format in Hive 0.13.0 and later STORED AS AVRO AVRO 형식 파일 포맷 저장 STORED AS JSONFILE Hive 4.0.0 이후 지원 Row Formats & SerDe "}}